---
title: 'Developping LLM Applications with LongChain'
date: 2024-01-24
permalink: /posts/2024/01/blog-post-4/
tags:
  - LLM
  - LongChain
---
LLM courses' notes


Chapter 1 : Introduction to LongChain & Chatbot Mechanics
======

The LangChain ecosystem 
======
We now lived in a world where we're spoiled for choice when it comes to choosing large language models of LLMs, for developping AI-powered applications. However, these LLMs differ based on their model architecture, training data, intended use cases, and prompting strategies. Additionally, these models ofter have to interact with other systems to retrieve data or monitor performance, which adds another layer of complexity. 
<br/><img src='/images/llm.png'>

What is LangChain ? 
------
Harrison Chase created LangChain in October 2022 to change all of that. It is an open-source framework for connecting : 
- LLMs
- data sources
- other functionality under a single unified syntax.

With LangChain, developpers can create scalable, modular LLM applications for almost any use. 

Objectives of this course 
------

LongChain encompasses an entire ecosystem of tools, but inthis course, we'll focus on : 
- core functionality of LangChain library.
- Chains and Tools for optimizing LLM output.
- Discussions on troubleshooting and evaluation techniques

LongChain is availiable in Python and JavaScript, but this course will only cover the Python version. 

Core components of LangChain 
------
1. a language model chosen by the developper (open-source models ou closed-source models)
2. prompts for tuning user inputs into model inputs
3. parsers and indexers for organizing data for easy retrieval.
4. chains and agents for creating workflows containing different components

Choose models
------
Hugging Face is huge repository of open source datasets, tools, and models ! 

Using language models hosted on Hugging Face is free, but using them in LangChain require a Hugging Face API token. 

**Creating a Hugging Face API Key** :
1. Sign up for a Hugging Face account
2. Navigate to [https://huggingface.co/settings/tokens](https://huggingface.co/settings/tokens)
3. Select new tokens and copy the key

To recap
------
- LangChain is a fantastic tool for working with natural languages.
- In the real world of development for production, it unlocks the ability for intelligent conversations with document and more abbilities for task automation, and different ways to analyze text data.
- it makes using AI easier and gives us greater control over the entire workflow. 
- Advantages of LangChain : it unifies the different models from different resources into a consistent, modular workflow.

Codes
------
LongChain has an `OpenAI class` and a `HuggingFaceHub class` for interacting with the respective APIs.

1. Hugging Face models in Langchain ! 

```ruby
from langchain_community.llms import HuggingFaceHub

# Set your Hugging Face API token 
huggingfacehub_api_token = ' '

# Define the LLM
llm = HuggingFaceHub(repo_id='tiiuae/falcon-7b-instruct', huggingfacehub_api_token=huggingfacehub_api_token)

# Predict the words following the text in question
question = 'Whatever you do, take care of your shoes'
output = llm.predict(question)
print(output)
```
2. OpenAI models in LangChain!

```ruby
from langchain_openai import OpenAI

# Set your API Key from OpenAI
openai_api_key = "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" 

# Define the LLM
llm = OpenAI(model_name="gpt-3.5-turbo-instruct", openai_api_key=openai_api_key)

# Predict the words following the text in question
question = 'Whatever you do, take care of your shoes'
output = llm.predict(question)

print(output)
```

## Prompting strategies for chatbots

Use LangChain to start implementing prompting strategies for chatbots, this will aplly both OpenAI chat models and open-source chat models from Hugging Face. 

### Finding the right model

Search the models section of Hugging Face and filter on Question Answering. Then, take note of the model name so it can be referenced in the code. 

There are so many fine-tuned models, which are trained on domain-specific datasets. 

## Prompt templates 

Prompt templates act as recipes for generating prompts from use inputs in a flexible and modular way (提示模板充当配方，以灵活和模块化的方式根据使用输入生成提示)

A template can include instructions, examples if we were wanting to few-shot prompt, and any additional context that might help the model complete the task.模板可以包含说明、示例（如果我们想要少量提示）以及可能帮助模型完成任务的任何其他上下文。) 

Prompt templates are created using LangChain's prompte template class. We start by creating a template string, which is structured to prompt the AI to answer a question. 

```ruby
from langchain.prompts import PromptTemplate

template = "You are an artificial intelligence assistant, answer the question. {question}"

prompt = PromptTemplate(template = template, input_variables = ["question"])
```

Here, the question field is defined for dynamic insertion later in the code. To convert this string into a prompt template for our model, we pass it to the `PromptTemplate`

Now we have our prompt template, let's integrate it into a model. 

## Integrating PromptTemplat with LLMs : LLMChain

Pass the prompt template and model to the LLMChain function : 

```ruby
from langchain.chains import LLMChain
from langchain_community.llms import HuggingFace

llm = HuggingFaceHub(repo_id = 'tiiuae/falcon-7b-instruct', huggingfacehub_api_token = huggingfacehub_api_token)
llm_chain = LLMChain(prompt = prompt, llm = llm)

# to begin passing user inputs, we call the .run() method on the chain, passing the input string 

question = "What is LangChain ?"
print(llm_chain.run(question))

```
We've run a question and answering task from end-to-end using LangChain. 

## Chat models using LangChain with OpenAI

LangChain also provides classes specifically designed to work with chat models, like `ChatPromptTemplate` and `ChatOpenAI`

```ruby
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate

llm = ChatOpenAI(temperature = 0, openai_api_key = openai_api_key)

prompt_template = ChatPromptTemplate.from_messages(
[
    ("system", "You are soto sen master Roshi."),
    ("human", "Respond to the question : {question}")
])

full_prompt = prompt_template.format_messages(question = "What is the sound of one hand clapping ?")

llm(full_prompt)
```

The `ChatOpenAI` provides chat-specific functionality than the standard OpenAi class. We can instantiate the model as normal, making sure to provide our OpenAI API key. 

To generate a chat prompt template for the model, we can call the `.from_messages()`method on `ChatPromptTemplate`. 

Inside, we can provide messages to the different OpenAI chat roles, including systems humman, and AI. 

Finally, inputs can be passed to the template using `.format` messages() method. We'll pass the prompt to the model to ~~view the model response~~. 